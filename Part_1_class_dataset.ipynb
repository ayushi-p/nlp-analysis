{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC1lr60UHGIE"
   },
   "source": [
    "### **Import modules and read files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juBNynXMGctY",
    "outputId": "b482a383-ca48-46c7-e203-29c8fa34dd59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12156\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12156\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\12156\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\12156\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YwSm_ijiHYe0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files \n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p1ChNDMMHnSx"
   },
   "outputs": [],
   "source": [
    "# read tweet data\n",
    "tweet_data = pd.read_csv('sentiment_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "N78gMz9w5DYv",
    "outputId": "718dec04-367d-4bf6-e343-c69c8d1b3a7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>Josh Jenkins is looking forward to TAB Breeder...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @MianUsmanJaved: Congratulations Pakistan o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @PEPalerts: This September, @YESmag is taki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @david_gaibis: Newly painted walls, thanks ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @CedricFeschotte: Excited to announce: as o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text  label\n",
       "0  7.680980e+17  Josh Jenkins is looking forward to TAB Breeder...      1\n",
       "1  7.680980e+17  RT @MianUsmanJaved: Congratulations Pakistan o...      1\n",
       "2  7.680980e+17  RT @PEPalerts: This September, @YESmag is taki...      1\n",
       "3  7.680980e+17  RT @david_gaibis: Newly painted walls, thanks ...      1\n",
       "4  7.680980e+17  RT @CedricFeschotte: Excited to announce: as o...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2mxtWnPZ8Yf",
    "outputId": "10d5c58b-b03c-4290-b64b-6144843953b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-G-9OrbKexq"
   },
   "source": [
    "### **Data cleaning**\n",
    "\n",
    "In this section, the dataset provided (*`sentiment_analysis.csv`*) will be cleaned to remove html tags, attributes, mentions, URL, stop words, etc. In addition, all words will be converted to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0_z_qCoL_JE"
   },
   "source": [
    "**Defining functions to clean dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DErSYdDDKmDQ"
   },
   "outputs": [],
   "source": [
    "def parser(text):\n",
    "  \"\"\"\n",
    "    removes html tags and attributes using beautifulSoup html.parser,\n",
    "    returns output as text\n",
    "  \"\"\"\n",
    "  soup = BeautifulSoup(text,'html.parser')\n",
    "  return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JOhFUnO7Tc_M"
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "  \"\"\"\n",
    "    normalizes unicode character to regular text\n",
    "  \"\"\"\n",
    "  # read ascii characters using NFKD method, then decode back to string\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J2X5t5DUT92C"
   },
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LsVeItGhUqMZ"
   },
   "outputs": [],
   "source": [
    "def remove_mentions(text):\n",
    "    \n",
    "    #for usernames with two \"_\"\n",
    "    text = re.sub(r'@[A-Za-z0-9]+_[A-Za-z0-9]+_[A-Za-z0-9]+','',text) \n",
    "    \n",
    "    #for usernames with one \"_\"\n",
    "    text = re.sub(r'@[A-Za-z0-9]+_[A-Za-z0-9]+','',text)\n",
    "    \n",
    "    #for usernames with no \"_\"\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ir-5VQoNVdeA"
   },
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    text = re.sub(r'-','',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Jgy_oM1kVgtx"
   },
   "outputs": [],
   "source": [
    "def remove_nonletter(text):\n",
    "    \"\"\"\n",
    "    removes any item that is not in the a-z or A-Z\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z ]+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_WBQyqtWo0M"
   },
   "source": [
    "**Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uleYaODpWtHd",
    "outputId": "660a9be2-8eff-4d42-d206-c08373d68fc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Josh Jenkins is looking forward to TAB Breeder...\n",
       "1    RT @MianUsmanJaved: Congratulations Pakistan o...\n",
       "2    RT @PEPalerts: This September, @YESmag is taki...\n",
       "3    RT @david_gaibis: Newly painted walls, thanks ...\n",
       "4    RT @CedricFeschotte: Excited to announce: as o...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter tweet text\n",
    "tweet_text = tweet_data[\"text\"]\n",
    "tweet_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKXQZB6CX9qm",
    "outputId": "90c60001-b148-47cb-ce98-3fed4b56c481"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    josh jenkins is looking forward to tab breeder...\n",
       "1    rt @mianusmanjaved: congratulations pakistan o...\n",
       "2    rt @pepalerts: this september, @yesmag is taki...\n",
       "3    rt @david_gaibis: newly painted walls, thanks ...\n",
       "4    rt @cedricfeschotte: excited to announce: as o...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tweet text to lowercase\n",
    "tweet_text_lower = tweet_text.astype(str).str.lower()\n",
    "tweet_text_lower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8LrvLVvTXZv6"
   },
   "outputs": [],
   "source": [
    "# clean tweet text using created functions\n",
    "tweet_text_cleaned = tweet_text_lower.apply(parser)\n",
    "tweet_text_cleaned = tweet_text_cleaned.apply(normalize)\n",
    "tweet_text_cleaned = tweet_text_cleaned.apply(remove_URL)\n",
    "tweet_text_cleaned = tweet_text_cleaned.apply(remove_mentions)\n",
    "tweet_text_cleaned = tweet_text_cleaned.apply(remove_spaces)\n",
    "tweet_text_cleaned = tweet_text_cleaned.apply(remove_nonletter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5Uy2UTTEkXP",
    "outputId": "a1b9ea2f-044d-425f-fd21-1d849a949c09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    josh jenkins is looking forward to tab breeder...\n",
       "1    rt   congratulations pakistan on becoming  no ...\n",
       "2    rt   this september  is taking you to maine me...\n",
       "3    rt   newly painted walls  thanks a million to ...\n",
       "4    rt   excited to announce  as of july   feschot...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vVTmnoUqEqMx",
    "outputId": "e27430a5-0f39-445e-ab61-81daf6e01c6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>Josh Jenkins is looking forward to TAB Breeder...</td>\n",
       "      <td>1</td>\n",
       "      <td>josh jenkins is looking forward to tab breeder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @MianUsmanJaved: Congratulations Pakistan o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   congratulations pakistan on becoming  no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @PEPalerts: This September, @YESmag is taki...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   this september  is taking you to maine me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @david_gaibis: Newly painted walls, thanks ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   newly painted walls  thanks a million to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @CedricFeschotte: Excited to announce: as o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   excited to announce  as of july   feschot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text  label  \\\n",
       "0  7.680980e+17  Josh Jenkins is looking forward to TAB Breeder...      1   \n",
       "1  7.680980e+17  RT @MianUsmanJaved: Congratulations Pakistan o...      1   \n",
       "2  7.680980e+17  RT @PEPalerts: This September, @YESmag is taki...      1   \n",
       "3  7.680980e+17  RT @david_gaibis: Newly painted walls, thanks ...      1   \n",
       "4  7.680980e+17  RT @CedricFeschotte: Excited to announce: as o...      1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  josh jenkins is looking forward to tab breeder...  \n",
       "1  rt   congratulations pakistan on becoming  no ...  \n",
       "2  rt   this september  is taking you to maine me...  \n",
       "3  rt   newly painted walls  thanks a million to ...  \n",
       "4  rt   excited to announce  as of july   feschot...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat regular tweet text with cleaned text\n",
    "tweet_data_2 = pd.concat([tweet_data, tweet_text_cleaned], axis=1)\n",
    "tweet_data_2.columns.values[-1] = 'cleaned_text'\n",
    "tweet_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50pBZyICI3Tw"
   },
   "source": [
    "**Remove stop words**\n",
    "\n",
    "In this subsection, I will be removing stop words in the tweet text, they are words that do not add any meaning to the sentence such as a, an, the, this, of, etc. I will be doing this using the list of stop words from **NLTK** library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "097sATYRJvIW",
    "outputId": "77f2cf5d-31db-4a5f-a224-52ccc035cbbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tweets_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>Josh Jenkins is looking forward to TAB Breeder...</td>\n",
       "      <td>1</td>\n",
       "      <td>josh jenkins is looking forward to tab breeder...</td>\n",
       "      <td>josh jenkins looking forward tab breeders crow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @MianUsmanJaved: Congratulations Pakistan o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   congratulations pakistan on becoming  no ...</td>\n",
       "      <td>congratulations pakistan becoming testteam wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @PEPalerts: This September, @YESmag is taki...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   this september  is taking you to maine me...</td>\n",
       "      <td>september taking maine mendozas surprise thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @david_gaibis: Newly painted walls, thanks ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   newly painted walls  thanks a million to ...</td>\n",
       "      <td>newly painted walls thanks million custodial p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @CedricFeschotte: Excited to announce: as o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   excited to announce  as of july   feschot...</td>\n",
       "      <td>excited announce july feschotte lab relocating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text  label  \\\n",
       "0  7.680980e+17  Josh Jenkins is looking forward to TAB Breeder...      1   \n",
       "1  7.680980e+17  RT @MianUsmanJaved: Congratulations Pakistan o...      1   \n",
       "2  7.680980e+17  RT @PEPalerts: This September, @YESmag is taki...      1   \n",
       "3  7.680980e+17  RT @david_gaibis: Newly painted walls, thanks ...      1   \n",
       "4  7.680980e+17  RT @CedricFeschotte: Excited to announce: as o...      1   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  josh jenkins is looking forward to tab breeder...   \n",
       "1  rt   congratulations pakistan on becoming  no ...   \n",
       "2  rt   this september  is taking you to maine me...   \n",
       "3  rt   newly painted walls  thanks a million to ...   \n",
       "4  rt   excited to announce  as of july   feschot...   \n",
       "\n",
       "                            tweets_without_stopwords  \n",
       "0  josh jenkins looking forward tab breeders crow...  \n",
       "1  congratulations pakistan becoming testteam wor...  \n",
       "2  september taking maine mendozas surprise thank...  \n",
       "3  newly painted walls thanks million custodial p...  \n",
       "4  excited announce july feschotte lab relocating...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define set of nltk stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#adding new stopwords\n",
    "stop_words.add(\"i'm\")\n",
    "stop_words.add(\"they're\")\n",
    "stop_words.add(\"thats\")\n",
    "stop_words.add(\"tho\")\n",
    "stop_words.add(\"also\")\n",
    "stop_words.add(\"rt\")\n",
    "\n",
    "# create new column for tweet without stop words\n",
    "tweet_data_2['tweets_without_stopwords'] = tweet_data_2['cleaned_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "tweet_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knW2WQU3OWiu"
   },
   "source": [
    "**Perform lemmatization**\n",
    "\n",
    "Lemmatization is the process of grouping together words with the same root meaning into its base word for example leafs, leaves are grouped into leaf. I will perform this with the **WordNetLemmatizer()** class in NLTK lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "v4aSGjzvPQx_"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    words_in_each_tweet = word_tokenize(text)\n",
    "    final = [lemmatizer.lemmatize(word) for word in words_in_each_tweet]\n",
    "    lemmatized_tweets = ' '.join(final)\n",
    "    return lemmatized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HjJ6_2NdQNFZ",
    "outputId": "5305b132-e159-4379-ec24-39211e035249"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tweets_without_stopwords</th>\n",
       "      <th>tweets_with_lemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>Josh Jenkins is looking forward to TAB Breeder...</td>\n",
       "      <td>1</td>\n",
       "      <td>josh jenkins is looking forward to tab breeder...</td>\n",
       "      <td>josh jenkins looking forward tab breeders crow...</td>\n",
       "      <td>josh jenkins looking forward tab breeder crown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @MianUsmanJaved: Congratulations Pakistan o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   congratulations pakistan on becoming  no ...</td>\n",
       "      <td>congratulations pakistan becoming testteam wor...</td>\n",
       "      <td>congratulation pakistan becoming testteam worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @PEPalerts: This September, @YESmag is taki...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   this september  is taking you to maine me...</td>\n",
       "      <td>september taking maine mendozas surprise thank...</td>\n",
       "      <td>september taking maine mendozas surprise thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @david_gaibis: Newly painted walls, thanks ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   newly painted walls  thanks a million to ...</td>\n",
       "      <td>newly painted walls thanks million custodial p...</td>\n",
       "      <td>newly painted wall thanks million custodial pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.680980e+17</td>\n",
       "      <td>RT @CedricFeschotte: Excited to announce: as o...</td>\n",
       "      <td>1</td>\n",
       "      <td>rt   excited to announce  as of july   feschot...</td>\n",
       "      <td>excited announce july feschotte lab relocating...</td>\n",
       "      <td>excited announce july feschotte lab relocating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text  label  \\\n",
       "0  7.680980e+17  Josh Jenkins is looking forward to TAB Breeder...      1   \n",
       "1  7.680980e+17  RT @MianUsmanJaved: Congratulations Pakistan o...      1   \n",
       "2  7.680980e+17  RT @PEPalerts: This September, @YESmag is taki...      1   \n",
       "3  7.680980e+17  RT @david_gaibis: Newly painted walls, thanks ...      1   \n",
       "4  7.680980e+17  RT @CedricFeschotte: Excited to announce: as o...      1   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  josh jenkins is looking forward to tab breeder...   \n",
       "1  rt   congratulations pakistan on becoming  no ...   \n",
       "2  rt   this september  is taking you to maine me...   \n",
       "3  rt   newly painted walls  thanks a million to ...   \n",
       "4  rt   excited to announce  as of july   feschot...   \n",
       "\n",
       "                            tweets_without_stopwords  \\\n",
       "0  josh jenkins looking forward tab breeders crow...   \n",
       "1  congratulations pakistan becoming testteam wor...   \n",
       "2  september taking maine mendozas surprise thank...   \n",
       "3  newly painted walls thanks million custodial p...   \n",
       "4  excited announce july feschotte lab relocating...   \n",
       "\n",
       "                                  tweets_with_lemmer  \n",
       "0  josh jenkins looking forward tab breeder crown...  \n",
       "1  congratulation pakistan becoming testteam worl...  \n",
       "2  september taking maine mendozas surprise thank...  \n",
       "3  newly painted wall thanks million custodial pa...  \n",
       "4  excited announce july feschotte lab relocating...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_2['tweets_with_lemmer'] = tweet_data_2['tweets_without_stopwords'].apply(lemmatizing)\n",
    "tweet_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1Kfd7fgMijJ",
    "outputId": "67042ca3-7f36-4de0-dbb7-d0bdecf0cc20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         josh jenkins looking forward tab breeder crown...\n",
       "1         congratulation pakistan becoming testteam worl...\n",
       "2         september taking maine mendozas surprise thank...\n",
       "3         newly painted wall thanks million custodial pa...\n",
       "4         excited announce july feschotte lab relocating...\n",
       "                                ...                        \n",
       "550386                                     stop watching mm\n",
       "550387    poor old tom odell look like would know wrong ...\n",
       "550388           antsmasher smashed ant awesome game hjfjfi\n",
       "550389                        morning girl wonderful friday\n",
       "550390      bixbeat mixtape vol great artiste join movement\n",
       "Name: tweets_with_lemmer, Length: 550391, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_2.tweets_with_lemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3syXaVU6Zhht"
   },
   "source": [
    "### **Feature Engineering**\n",
    "\n",
    "In this section numerical features will be engineered from the lemmatized tweet text using **TF-IDF** (Term Frequency-Inverse Document Frequency) tecnique. \n",
    "\n",
    "TF-IDF is used to assign importance weight to each word in a document based on how frequent it appears in the document, words with high frequency have higher weigths (**TF**). On the otherhand, words are later down weighted based on how frequent they appear in a corpus (**IDF**). In our case each tweet text is considered as a **document** and the entire dataset is the **corpus**.\n",
    "\n",
    "I will perform this using the **TfidfVectorizer()** class in **sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "T1Z5NhhSMijJ"
   },
   "outputs": [],
   "source": [
    "##COUNT VECTORIZER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "lPB4sz9Jb3WX",
    "outputId": "f5407fa2-0e19-4a1e-d1b9-df9482125741"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>adorable</th>\n",
       "      <th>ago</th>\n",
       "      <th>album</th>\n",
       "      <th>almost</th>\n",
       "      <th>already</th>\n",
       "      <th>always</th>\n",
       "      <th>...</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wtf</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolutely  account  actually   ad  adorable  ago  album  almost  already  \\\n",
       "0         0.0      0.0       0.0  0.0       0.0  0.0    0.0     0.0      0.0   \n",
       "1         0.0      0.0       0.0  0.0       0.0  0.0    0.0     0.0      0.0   \n",
       "2         0.0      0.0       0.0  0.0       0.0  0.0    0.0     0.0      0.0   \n",
       "3         0.0      0.0       0.0  0.0       0.0  0.0    0.0     0.0      0.0   \n",
       "4         0.0      0.0       0.0  0.0       0.0  0.0    0.0     0.0      0.0   \n",
       "\n",
       "   always  ...  wow  wrong  wtf   ya  yeah  year  yes  yesterday  yet  young  \n",
       "0     0.0  ...  0.0    0.0  0.0  0.0   0.0   0.0  0.0        0.0  0.0    0.0  \n",
       "1     0.0  ...  0.0    0.0  0.0  0.0   0.0   0.0  0.0        0.0  0.0    0.0  \n",
       "2     0.0  ...  0.0    0.0  0.0  0.0   0.0   0.0  0.0        0.0  0.0    0.0  \n",
       "3     0.0  ...  0.0    0.0  0.0  0.0   0.0   0.0  0.0        0.0  0.0    0.0  \n",
       "4     0.0  ...  0.0    0.0  0.0  0.0   0.0   0.0  0.0        0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 600 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TERM FREQUENCY VECTORIZER\n",
    "# TF-IDF vectorizer to create a 1D vector for each tweet\n",
    "tweet_data_cleaned = tweet_data_2.tweets_with_lemmer\n",
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 600,\n",
    "                                      norm = 'l2',\n",
    "                                      use_idf = True,\n",
    "                                      smooth_idf = True)\n",
    "\n",
    "\n",
    "tfidf_vec = tfidf_vectorizer.fit_transform(tweet_data_cleaned.values.astype('U'))\n",
    "tfidf_array = tfidf_vec.toarray()\n",
    "\n",
    "# encodes tweet data\n",
    "TFIDF_features = pd.DataFrame(data=tfidf_array, columns = tfidf_vectorizer.get_feature_names_out())\n",
    "TFIDF_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "AcJ6ig4vMijK"
   },
   "outputs": [],
   "source": [
    "#MODEL IMPLEMENTATION https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier #Classification \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VB78w5qEMijK"
   },
   "outputs": [],
   "source": [
    "#Dataset and Target \n",
    "X = TFIDF_features\n",
    "y = tweet_data.label\n",
    "\n",
    "#Data Spltting\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGk4dRBgWKHs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "yZZMX8LfWKJ6",
    "outputId": "9b1363d8-6bf0-44f4-aa1e-6c7826fa1025"
   },
   "outputs": [],
   "source": [
    "#MODEL IMPLEMENTATION\n",
    "t_ = time.time()\n",
    "\n",
    "Logistic_model = LogisticRegression()\n",
    "Logistic_model.fit(x_train, y_train)\n",
    "score_logistic = Logistic_model.score(x_test, y_test)\n",
    "\n",
    "t1 = time.time()\n",
    "log_time = t1-t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = time.time()\n",
    "\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(x_train, y_train)\n",
    "score_nb = NB_model.score(x_test, y_test)\n",
    "\n",
    "t2 = time.time()\n",
    "nb_time = t2-t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = time.time()\n",
    "\n",
    "DT_model = DecisionTreeClassifier(random_state=0)\n",
    "DT_model.fit(x_train, y_train)\n",
    "score_dt = DT_model.score(x_test, y_test)\n",
    "\n",
    "t3 = time.time()\n",
    "dt_time = t3-t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = time.time()\n",
    "\n",
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(x_train, y_train)\n",
    "score_rf = RF_model.score(x_test, y_test)\n",
    "\n",
    "t4 = time.time()\n",
    "rf_time = t4-t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = time.time()\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "score_xgb = xgb_model.score(x_test, y_test)\n",
    "\n",
    "t5 = time.time()\n",
    "xgb_time = t5-t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = time.time()\n",
    "\n",
    "NN_model = MLPClassifier()\n",
    "NN_model.fit(x_train, y_train)\n",
    "score_NN = NN_model.score(x_test,y_test)\n",
    "\n",
    "t6 = time.time()\n",
    "nn_time = t6-t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM_model = SVC()\n",
    "# SVM_model.fit(x_train, y_train)\n",
    "# score_svm = SVM_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN_model = KNeighborsClassifier()\n",
    "# KNN_model.fit(x_train, y_train)\n",
    "# score_knn = KNN_model.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IYPmPj-39XK3"
   },
   "outputs": [],
   "source": [
    "#Display Results \n",
    "model_list = ['Logistic Regression', 'Naive Bayes', 'Decision Trees', 'Random Forest', 'XG Boost' ,'Neural Network']    # ,'SVM', KNN']\n",
    "accuracy_list = [score_logistic,score_nb,score_dt,score_rf, score_xgb,score_NN]                 # ,score_svm ,score_knn]\n",
    "time_list = [log_time, nb_time, dt_time, rf_time, xgb_time, nn_time]\n",
    "\n",
    "table = {'Classification Model': model_list,\n",
    "          'Accuracy': accuracy_list,\n",
    "        'Implementation time': time_list}\n",
    "table = pd.DataFrame(table)\n",
    "\n",
    "#Best model is xx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Implementation time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.925211</td>\n",
       "      <td>30.731428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.862510</td>\n",
       "      <td>7.792603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.917871</td>\n",
       "      <td>746.291499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.931322</td>\n",
       "      <td>1278.720651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XG Boost</td>\n",
       "      <td>0.916417</td>\n",
       "      <td>150.459553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.922722</td>\n",
       "      <td>1148.709273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Model  Accuracy  Implementation time\n",
       "0  Logistic Regression  0.925211            30.731428\n",
       "1          Naive Bayes  0.862510             7.792603\n",
       "2       Decision Trees  0.917871           746.291499\n",
       "3        Random Forest  0.931322          1278.720651\n",
       "4             XG Boost  0.916417           150.459553\n",
       "5       Neural Network  0.922722          1148.709273"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4Z8_OK9A9Xs2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....bootstrap=True, criterion=gini;, score=0.929 total time=15.8min\n",
      "[CV 2/5] END ....bootstrap=True, criterion=gini;, score=0.932 total time=15.4min\n",
      "[CV 3/5] END ....bootstrap=True, criterion=gini;, score=0.930 total time=15.3min\n",
      "[CV 4/5] END ....bootstrap=True, criterion=gini;, score=0.929 total time=15.3min\n",
      "[CV 5/5] END ....bootstrap=True, criterion=gini;, score=0.931 total time=15.4min\n",
      "[CV 1/5] END .bootstrap=True, criterion=entropy;, score=0.930 total time=14.7min\n",
      "[CV 2/5] END .bootstrap=True, criterion=entropy;, score=0.933 total time=14.6min\n",
      "[CV 3/5] END .bootstrap=True, criterion=entropy;, score=0.931 total time=14.6min\n",
      "[CV 4/5] END .bootstrap=True, criterion=entropy;, score=0.930 total time=14.7min\n",
      "[CV 5/5] END .bootstrap=True, criterion=entropy;, score=0.931 total time=14.7min\n",
      "[CV 1/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 2/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 3/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 4/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 5/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 1/5] END ...bootstrap=False, criterion=gini;, score=0.928 total time=25.2min\n",
      "[CV 2/5] END ...bootstrap=False, criterion=gini;, score=0.931 total time=25.2min\n",
      "[CV 3/5] END ...bootstrap=False, criterion=gini;, score=0.928 total time=25.2min\n",
      "[CV 4/5] END ...bootstrap=False, criterion=gini;, score=0.928 total time=25.3min\n",
      "[CV 5/5] END ...bootstrap=False, criterion=gini;, score=0.929 total time=25.4min\n",
      "[CV 1/5] END bootstrap=False, criterion=entropy;, score=0.928 total time=23.7min\n",
      "[CV 2/5] END bootstrap=False, criterion=entropy;, score=0.932 total time=23.7min\n",
      "[CV 3/5] END bootstrap=False, criterion=entropy;, score=0.929 total time=23.6min\n",
      "[CV 4/5] END bootstrap=False, criterion=entropy;, score=0.928 total time=23.8min\n",
      "[CV 5/5] END bootstrap=False, criterion=entropy;, score=0.929 total time=24.0min\n",
      "[CV 1/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.8s\n",
      "[CV 2/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.8s\n",
      "[CV 3/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 4/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 5/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter tuning best model: grid search CV -- accuracy\n",
    "grid_values = {'criterion':['gini','entropy','log'],'bootstrap':[True,False]}\n",
    "               #,'n_estimators':[80,100],'max_features':['sqrt','log2','None']}\n",
    "    \n",
    "grid = GridSearchCV(RF_model, param_grid = grid_values,cv=5,scoring = 'accuracy', refit = True, verbose = 3)\n",
    "best_result = grid.fit(x_train, y_train) #cross-validation dataset\n",
    "\n",
    "#Best hyperparameters are xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "5I2rbmR4GisE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....bootstrap=True, criterion=gini;, score=0.947 total time=19.4min\n",
      "[CV 2/5] END ....bootstrap=True, criterion=gini;, score=0.950 total time=15.4min\n",
      "[CV 3/5] END ....bootstrap=True, criterion=gini;, score=0.948 total time=15.3min\n",
      "[CV 4/5] END ....bootstrap=True, criterion=gini;, score=0.947 total time=15.4min\n",
      "[CV 5/5] END ....bootstrap=True, criterion=gini;, score=0.948 total time=15.5min\n",
      "[CV 1/5] END .bootstrap=True, criterion=entropy;, score=0.947 total time=15.6min\n",
      "[CV 2/5] END .bootstrap=True, criterion=entropy;, score=0.950 total time=16.9min\n",
      "[CV 3/5] END .bootstrap=True, criterion=entropy;, score=0.948 total time=17.2min\n",
      "[CV 4/5] END .bootstrap=True, criterion=entropy;, score=0.948 total time=17.0min\n",
      "[CV 5/5] END .bootstrap=True, criterion=entropy;, score=0.948 total time=17.1min\n",
      "[CV 1/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 2/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 3/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 4/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 5/5] END .......bootstrap=True, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 1/5] END ...bootstrap=False, criterion=gini;, score=0.946 total time=29.5min\n",
      "[CV 2/5] END ...bootstrap=False, criterion=gini;, score=0.948 total time=29.7min\n",
      "[CV 3/5] END ...bootstrap=False, criterion=gini;, score=0.946 total time=29.4min\n",
      "[CV 4/5] END ...bootstrap=False, criterion=gini;, score=0.946 total time=29.5min\n",
      "[CV 5/5] END ...bootstrap=False, criterion=gini;, score=0.946 total time=30.7min\n",
      "[CV 1/5] END bootstrap=False, criterion=entropy;, score=0.946 total time=27.9min\n",
      "[CV 2/5] END bootstrap=False, criterion=entropy;, score=0.948 total time=28.6min\n",
      "[CV 3/5] END bootstrap=False, criterion=entropy;, score=0.947 total time=28.1min\n",
      "[CV 4/5] END bootstrap=False, criterion=entropy;, score=0.946 total time=28.1min\n",
      "[CV 5/5] END bootstrap=False, criterion=entropy;, score=0.947 total time=28.2min\n",
      "[CV 1/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.8s\n",
      "[CV 2/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.8s\n",
      "[CV 3/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.8s\n",
      "[CV 4/5] END ......bootstrap=False, criterion=log;, score=nan total time=   0.7s\n",
      "[CV 5/5] END ......bootstrap=False, criterion=log;, score=nan total time=   1.1s\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter tuning best model: grid search CV -- f1\n",
    "grid_values = {'criterion':['gini','entropy','log'],'bootstrap':[True,False]}\n",
    "               #,'n_estimators':[80,100],'max_features':['sqrt','log2','None']}\n",
    "    \n",
    "grid = GridSearchCV(RF_model, param_grid = grid_values,cv=5,scoring = 'f1', refit = True, verbose = 3)\n",
    "best_result = grid.fit(x_train, y_train) #cross-validation dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Bootstrap</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Mean Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.948</td>\n",
       "      <td>15.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>14.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log</td>\n",
       "      <td>True</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Nan</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>25.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entropy</td>\n",
       "      <td>False</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>23.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>log</td>\n",
       "      <td>False</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Nan</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Criterion  Bootstrap Mean Accuracy Mean F1  Mean Runtime\n",
       "0      gini       True        0.9302   0.948         15.44\n",
       "1   entropy       True         0.931  0.9482         14.66\n",
       "2       log       True           Nan     Nan          0.70\n",
       "3      gini      False        0.9288  0.9464         25.26\n",
       "4   entropy      False         0.929  0.9468         23.76\n",
       "5       log      False           Nan     Nan          0.70"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = ['gini','entropy','log']\n",
    "bootstrap = [True, False, None] \n",
    "\n",
    "\n",
    "data = [['gini',True, np.mean([0.929,0.932,0.930,0.929,0.931]),np.mean([0.947,0.950,0.948,0.947,0.948]),np.mean([15.8,15.4,15.3,15.3,15.4])],\n",
    "        ['entropy',True, np.mean([0.930,0.933,0.931,0.930,0.931]),np.mean([0.947,0.950,0.948,0.948,0.948]),np.mean([14.7,14.6,14.6,14.7,14.7])],\n",
    "        ['log',True,'Nan','Nan', np.mean([0.7,0.7,0.7,0.7,0.7])],\n",
    "        \n",
    "        ['gini',False, np.mean([0.928,0.931,0.928,0.928,0.929]),np.mean([0.946,0.948,0.946,0.946,0.946]),np.mean([25.2,25.2,25.2,25.3,25.4])],\n",
    "        ['entropy',False, np.mean([0.928,0.932,0.928,0.928,0.929]),np.mean([0.946,0.948,0.947,0.946,0.947]),np.mean([23.7,23.7,23.6,23.8,24])],\n",
    "        ['log',False,'Nan','Nan',np.mean([0.7,0.7,0.7,0.7,0.7])],\n",
    "       \n",
    "       ]\n",
    "df = pd.DataFrame(data)\n",
    "df = pd.DataFrame(data, columns=['Criterion', 'Bootstrap', 'Mean Accuracy', 'Mean F1', 'Mean Runtime'])\n",
    "df\n",
    "\n",
    "#Best model  is Random Forest - Critertion = Entropy, Bootstrap = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_model_jlib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install mlxtend\n",
    "# import joblib\n",
    "# import sys\n",
    "# sys.modules['sklearn.externals.joblib'] = joblib\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "# loading dependecy\n",
    "import pickle\n",
    "#from sklearn.externals import joblib\n",
    "\n",
    "# saving our model\n",
    "joblib.dump(RF_model , 'RF_model_jlib')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
